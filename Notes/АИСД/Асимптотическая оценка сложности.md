### Асимптота

**Асимптота** — это прямая линия, к которой неограниченно приближается график функции при стремлении аргумента к бесконечности или к определенной точке разрыва, но никогда не пересекает её (или пересекает, но бесконечное количество раз).

### Порядок роста

**Порядок роста** описывает то, как сложность алгоритма (чаще всего время выполнения или потребление памяти) увеличивается с ростом размера входных данных (`n`). Для его описания используется **O-нотация** (от нем. «Ordnung» — порядок): `O(f(n))`, где `f(n)` — функция, выражающая сложность алгоритма.

---

## Асимптотические оценки сложности

Пусть `f(n)` (или `T(n)`) — функция, оценивающая время работы алгоритма. Асимптотический анализ позволяет найти другую функцию `g(n)`, которая описывает поведение `f(n)` при больших `n`.

### 1. O-нотация (О-большое) — Оценка сверху

> `f(n) = O(g(n))` тогда и только тогда, когда  
> `∃ c > 0, n₀ > 0 : ∀ n > n₀` выполняется `0 <= f(n) <= c * g(n)`

**Смысл:** Функция `g(n)` является **асимптотической верхней границей** для `f(n)`. Начиная с некоторого `n₀`, `f(n)` всегда лежит между `0` и `c * g(n)`.

**На языке алгоритмов:** "Алгоритм работает **не медленнее**, чем `g(n)`".

---

### 2. Ω-нотация (Омега) — Оценка снизу

> `f(n) = Ω(g(n))` тогда и только тогда, когда  
> `∃ c > 0, n₀ > 0 : ∀ n > n₀` выполняется `0 <= c * g(n) <= f(n)`

**Смысл:** Функция `g(n)` является **асимптотической нижней границей** для `f(n)`. Начиная с некоторого `n₀`, `f(n)` всегда лежит выше, чем `c * g(n)`.

**На языке алгоритмов:** "Алгоритм работает **не быстрее**, чем `g(n)`".

---

### 3. Θ-нотация (Тета) — Точная оценка

> `f(n) = Θ(g(n))` тогда и только тогда, когда  
> `∃ c₁ > 0, c₂ > 0, n₀ > 0 : ∀ n > n₀` выполняется `0 <= c₂ * g(n) <= f(n) <= c₁ * g(n)`

**Смысл:** Функция `g(n)` является **точной асимптотической оценкой** для `f(n)`. Начиная с некоторого `n₀`, `f(n)` "зажата" между `c₂ * g(n)` и `c₁ * g(n)`.

**На языке алгоритмов:** "Алгоритм работает **примерно как `g(n)`**".

---

## 🔧 Свойства O-нотации

1. **Сложность суммы функций:**  
    `f₁(n) + f₂(n) = O( max(g₁(n), g₂(n)) )`
    
    > _Суммируя сложности, учитываем бОльшую из функций порядка роста._
    
2. **Сложность произведения функций:**  
    `f₁(n) * f₂(n) = O( g₁(n) * g₂(n) )`
    
    > _Сложность произведения равна произведению сложностей._
    
3. **Умножение на константу:**  
    `f₁(n) * c = O( g₁(n) )`, где `c = const`
    
    > _Константные множители в O-нотации отбрасываются._
    
4. **Сложение с константой:**  
    `f₁(n) + c = O( g₁(n) )`, где `c = const`
    
    > _Константные слагаемые в O-нотации отбрасываются._
    
5. **Теорема о связи O, Ω и Θ:**  
    `f(n) = Θ(g(n))` **⇔** `f(n) = O(g(n))` и `f(n) = Ω(g(n))`
    
    > _Точная оценка существует тогда и только тогда, когда верхняя и нижняя оценки совпадают._
    

---
